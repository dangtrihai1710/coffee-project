import io
import numpy as np
import uuid
from datetime import datetime
from PIL import Image
from flask import Flask, request, jsonify
from flask_cors import CORS
import tensorflow as tf
import os
import cv2  # ƒê·∫£m b·∫£o ƒë√£ c√†i ƒë·∫∑t OpenCV b·∫±ng l·ªánh: pip install opencv-python

app = Flask(__name__)
CORS(app)

# ============ ƒê·ªãnh nghƒ©a c√°c model ============

# 1) Model 1: Ph√¢n bi·ªát coffee vs not_coffee
MODEL_COFFEE_PATH = "coffee_vs_notcoffee.keras"
try:
    model_coffee = tf.keras.models.load_model(MODEL_COFFEE_PATH)
    print("Model 1 (coffee vs not_coffee) ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.")
except Exception as e:
    print(f"L·ªói khi t·∫£i model_coffee: {e}")

# 2) Model 2: Ph√¢n lo·∫°i b·ªánh l√° c√† ph√™
MODEL_DISEASE_PATH = "coffee_resnet50_model_final.h5"
LABELS_DISEASE = [
    "C√¢y kho·∫ª (kh√¥ng b·ªánh)",
    "B·ªánh miner",
    "B·ªánh g·ªâ s·∫Øt",
    "B·ªánh phoma",
    "B·ªánh cercospora"
]
try:
    model_disease = tf.keras.models.load_model(MODEL_DISEASE_PATH)
    print("Model 2 (b·ªánh l√° c√† ph√™) ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.")
except Exception as e:
    print(f"L·ªói khi t·∫£i model_disease: {e}")

# ============ H√†m ti·ªÅn x·ª≠ l√Ω ·∫£nh ============

IMG_SIZE = (224, 224)

def preprocess_image(image, target_size=IMG_SIZE, is_coffee_model=True):
    """
    Ti·ªÅn x·ª≠ l√Ω ·∫£nh cho c√°c model v·ªõi c√°c y√™u c·∫ßu kh√°c nhau
    
    Args:
    - image: PIL Image object
    - target_size: K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu ra
    - is_coffee_model: Ki·ªÉm tra model coffee hay disease
    
    Returns:
    - Numpy array ·∫£nh ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a
    """
    # Thay ƒë·ªïi k√≠ch th∆∞·ªõc ·∫£nh
    image = image.resize(target_size)
    
    # Chuy·ªÉn sang numpy array
    image_array = np.array(image)
    
    # ƒê·∫£m b·∫£o 3 k√™nh m√†u
    if image_array.shape[-1] == 4:
        image_array = image_array[..., :3]
    
    # Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu
    image_array = image_array.astype("float32")
    
    # Preprocessing kh√°c nhau cho t·ª´ng model
    if is_coffee_model:
        # Model coffee vs not_coffee: normalize v·ªÅ [0, 1]
        image_array = image_array / 255.0
    else:
        # Model b·ªánh l√°: s·ª≠ d·ª•ng preprocess_input c·ªßa ResNet50
        # Th√™m batch dimension tr∆∞·ªõc khi preprocess
        image_array = np.expand_dims(image_array, axis=0)
        image_array = tf.keras.applications.resnet50.preprocess_input(image_array)
        # Tr·∫£ v·ªÅ batch dimension ƒë√£ ƒë∆∞·ª£c th√™m
        return image_array
    
    # Th√™m batch dimension
    image_array = np.expand_dims(image_array, axis=0)
    
    return image_array

def preprocess_for_natural_environment(image, target_size=IMG_SIZE):
    """
    Ti·ªÅn x·ª≠ l√Ω ƒë·∫∑c bi·ªát cho ·∫£nh trong m√¥i tr∆∞·ªùng t·ª± nhi√™n
    """
    # C·∫£i thi·ªán ƒë·ªô t∆∞∆°ng ph·∫£n
    image_array = np.array(image)
    
    # √Åp d·ª•ng CLAHE (Contrast Limited Adaptive Histogram Equalization)
    lab = cv2.cvtColor(image_array, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    
    enhanced = cv2.merge([l, a, b])
    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)
    
    # Resize v√† normalize
    enhanced_pil = Image.fromarray(enhanced)
    enhanced_pil = enhanced_pil.resize(target_size)
    
    image_array = np.array(enhanced_pil).astype("float32")
    
    # Normalize
    image_array = image_array / 255.0
    image_array = np.expand_dims(image_array, axis=0)
    
    return image_array

# ============ B·ªô l·ªçc ƒë·∫ßu v√†o c·∫£i thi·ªán ============

def detect_coffee_leaves_in_natural_environment(image):
    """
    C·∫£i thi·ªán nh·∫≠n di·ªán l√° c√† ph√™ trong m√¥i tr∆∞·ªùng t·ª± nhi√™n
    """
    image_np = np.array(image)
    
    # Chuy·ªÉn sang HSV ƒë·ªÉ ph√¢n t√≠ch m√†u s·∫Øc t·ªët h∆°n
    hsv = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV)
    
    # ƒê·ªãnh nghƒ©a ph·∫°m vi m√†u xanh l√° c√¢y (HSV)
    lower_green = np.array([35, 40, 40])
    upper_green = np.array([85, 255, 255])
    
    # T·∫°o mask cho m√†u xanh l√°
    green_mask = cv2.inRange(hsv, lower_green, upper_green)
    
    # T√≠nh t·ª∑ l·ªá m√†u xanh l√°
    green_ratio = np.sum(green_mask > 0) / (image_np.shape[0] * image_np.shape[1])
    
    # N·∫øu c√≥ ƒë·ªß m√†u xanh l√° (>25%), c√≥ th·ªÉ l√† l√° c√† ph√™
    if green_ratio < 0.25:
        return False
    
    # Ph√°t hi·ªán c·∫°nh ƒë·ªÉ t√¨m h√¨nh d·∫°ng l√°
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    
    # T√¨m contours
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Ki·ªÉm tra c√≥ √≠t nh·∫•t m·ªôt contour c√≥ k√≠ch th∆∞·ªõc h·ª£p l√Ω
    valid_leaf_found = False
    for contour in contours:
        area = cv2.contourArea(contour)
        if area > 800:  # Di·ªán t√≠ch t·ªëi thi·ªÉu cho m·ªôt l√°
            # T√≠nh t·ª∑ l·ªá khung h√¨nh
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = float(w) / h
            
            # L√° c√† ph√™ th∆∞·ªùng c√≥ t·ª∑ l·ªá 1.2 - 3.5
            if 1.2 <= aspect_ratio <= 3.5:
                valid_leaf_found = True
                break
    
    return valid_leaf_found

def has_extreme_non_leaf_features(image):
    """
    Ph√°t hi·ªán c√°c ƒë·∫∑c ƒëi·ªÉm c·ª±c ƒëoan r√µ r√†ng kh√¥ng ph·∫£i l√° c√¢y
    X√©t c·∫£ m√†u s·∫Øc v√† h√¨nh d·∫°ng ƒë·ªÉ x√°c ƒë·ªãnh
    """
    # Chuy·ªÉn ƒë·ªïi ·∫£nh sang array
    image_np = np.array(image)
    
    # --- Ki·ªÉm tra m√†u s·∫Øc ---
    # Ki·ªÉm tra t·ª∑ l·ªá m√†u xanh l√° c√¢y
    g_channel = image_np[:, :, 1].astype(float)
    r_channel = image_np[:, :, 0].astype(float)
    b_channel = image_np[:, :, 2].astype(float)
    
    # T√≠nh t·ª∑ l·ªá m√†u xanh l√° trong ·∫£nh
    green_pixels = np.sum((g_channel > r_channel*1.1) & (g_channel > b_channel*1.1))
    total_pixels = image_np.shape[0] * image_np.shape[1]
    green_ratio = green_pixels / total_pixels
    
    # Ki·ªÉm tra t·ª∑ l·ªá m√†u n√¢u (ƒë·∫∑c tr∆∞ng c·ªßa l√° b·ªã b·ªánh)
    brown_pixels = np.sum((r_channel > 100) & (g_channel < 100) & (b_channel < 100))
    brown_ratio = brown_pixels / total_pixels
    
    # Ki·ªÉm tra ƒë·ªô s√°ng
    brightness = np.mean(image_np) / 255.0
    
    # Ki·ªÉm tra ƒë·ªô l·ªách chu·∫©n m√†u
    color_std = np.std(image_np, axis=(0, 1))
    
    # --- Ki·ªÉm tra h√¨nh d·∫°ng ---
    # Chuy·ªÉn ·∫£nh sang grayscale ƒë·ªÉ ph√°t hi·ªán c·∫°nh
    gray_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    
    # Ph√°t hi·ªán c·∫°nh b·∫±ng Canny Edge Detection
    edges = cv2.Canny(gray_image, 100, 200)
    
    # T√¨m c√°c ƒë∆∞·ªùng vi·ªÅn (contours)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # N·∫øu kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng vi·ªÅn n√†o, c√≥ th·ªÉ kh√¥ng ph·∫£i l√°
    if len(contours) == 0:
        return True
    
    # L·∫•y ƒë∆∞·ªùng vi·ªÅn l·ªõn nh·∫•t (gi·∫£ ƒë·ªãnh l√† vi·ªÅn c·ªßa l√°)
    largest_contour = max(contours, key=cv2.contourArea)
    
    # T√≠nh di·ªán t√≠ch v√† chu vi c·ªßa ƒë∆∞·ªùng vi·ªÅn
    area = cv2.contourArea(largest_contour)
    perimeter = cv2.arcLength(largest_contour, True)
    
    # Ki·ªÉm tra ƒë·ªô ph·ª©c t·∫°p c·ªßa ƒë∆∞·ªùng vi·ªÅn (compactness)
    # compactness = perimeter^2 / area (gi√° tr·ªã th·∫•p h∆°n nghƒ©a l√† h√¨nh d·∫°ng ƒë∆°n gi·∫£n h∆°n)
    if area > 0:  # Tr√°nh chia cho 0
        compactness = (perimeter ** 2) / area
    else:
        compactness = float('inf')
    
    # T√≠nh t·ª∑ l·ªá chi·ªÅu d√†i/chi·ªÅu r·ªông
    x, y, w, h = cv2.boundingRect(largest_contour)
    aspect_ratio = float(w) / h if h > 0 else float('inf')
    
    # --- K·∫øt h·ª£p c√°c ti√™u ch√≠ ---
    # 1. Ki·ªÉm tra m√†u s·∫Øc: N·∫øu kh√¥ng c√≥ m√†u xanh v√† kh√¥ng c√≥ m√†u n√¢u
    color_condition = green_ratio < 0.15 and brown_ratio < 0.08
    
    # 2. Ki·ªÉm tra ƒë·ªô s√°ng: N·∫øu ·∫£nh qu√° t·ªëi ho·∫∑c qu√° s√°ng
    brightness_condition = brightness < 0.05 or brightness > 0.95
    
    # 3. Ki·ªÉm tra ƒë·ªô l·ªách chu·∫©n m√†u: N·∫øu ·∫£nh g·∫ßn nh∆∞ tr·∫Øng ƒëen
    color_std_condition = np.all(color_std < 20)
    
    # 4. Ki·ªÉm tra h√¨nh d·∫°ng:
    # - L√° c√† ph√™ th∆∞·ªùng c√≥ t·ª∑ l·ªá chi·ªÅu d√†i/chi·ªÅu r·ªông t·ª´ 1.2 ƒë·∫øn 3.5
    # - L√° c√≥ h√¨nh d·∫°ng t∆∞∆°ng ƒë·ªëi ƒë∆°n gi·∫£n (compactness th·∫•p, th∆∞·ªùng < 25)
    shape_condition = not (1.2 <= aspect_ratio <= 3.5 and compactness < 25)
    
    # N·∫øu ·∫£nh kh√¥ng c√≥ m√†u s·∫Øc ƒë·∫∑c tr∆∞ng c·ªßa l√° (xanh ho·∫∑c n√¢u)
    # v√† kh√¥ng c√≥ h√¨nh d·∫°ng gi·ªëng l√°, th√¨ coi l√† kh√¥ng ph·∫£i l√°
    if color_condition and shape_condition:
        # K·∫øt h·ª£p th√™m c√°c ƒëi·ªÅu ki·ªán ƒë·ªô s√°ng v√† ƒë·ªô l·ªách chu·∫©n m√†u
        if brightness_condition or color_std_condition:
            return True
    
    return False

def enhanced_leaf_detection(image):
    """
    C·∫£i thi·ªán ph√°t hi·ªán l√° c√† ph√™ v·ªõi nhi·ªÅu k·ªπ thu·∫≠t
    """
    # Ki·ªÉm tra c√°c ƒë·∫∑c ƒëi·ªÉm c·ª±c ƒëoan kh√¥ng ph·∫£i l√°
    if has_extreme_non_leaf_features(image):
        return False
    
    # Ki·ªÉm tra m√¥i tr∆∞·ªùng t·ª± nhi√™n
    return detect_coffee_leaves_in_natural_environment(image)

# ============ Route m·∫∑c ƒë·ªãnh ============

@app.route("/")
def home():
    return "API Cascade: model1 (coffee vs not_coffee) => model2 (disease)! - Phi√™n b·∫£n c·∫£i thi·ªán cho m√¥i tr∆∞·ªùng t·ª± nhi√™n"

# ============ Routes x√°c th·ª±c ============

@app.route("/auth/login", methods=["POST"])
def login():
    data = request.get_json()
    
    # Demo ƒë∆°n gi·∫£n: ki·ªÉm tra n·∫øu email/pass l√† demo
    if data.get('email') == 'demo@example.com' and data.get('password') == 'password':
        return jsonify({
            "success": True,
            "token": "demo_token_12345",
            "user": {
                "id": "12345",
                "fullName": "Ng∆∞·ªùi D√πng Demo",
                "email": "demo@example.com",
                "phone": "0123456789",
                "createdAt": datetime.now().isoformat()
            }
        })
    
    return jsonify({"success": False, "message": "Email ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng"}), 401

@app.route("/auth/register", methods=["POST"])
def register():
    data = request.get_json()
    
    # Ki·ªÉm tra email ƒë√£ t·ªìn t·∫°i
    if data.get('email') == 'demo@example.com':
        return jsonify({"success": False, "message": "Email ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng"}), 400
    
    # T·∫°o user m·ªõi
    user = {
        "id": str(uuid.uuid4()),
        "fullName": data.get('fullName', ''),
        "email": data.get('email', ''),
        "phone": data.get('phone', ''),
        "createdAt": datetime.now().isoformat()
    }
    
    return jsonify({
        "success": True,
        "token": f"token_{user['id']}",
        "user": user
    })

@app.route("/auth/reset-password", methods=["POST"])
def reset_password():
    data = request.get_json()
    
    # Demo ch·ªâ tr·∫£ v·ªÅ th√†nh c√¥ng
    return jsonify({
        "success": True,
        "message": "ƒê√£ g·ª≠i email ƒë·∫∑t l·∫°i m·∫≠t kh·∫©u."
    })

@app.route("/auth/update-profile", methods=["PUT"])
def update_profile():
    data = request.get_json()
    
    # Demo tr·∫£ v·ªÅ th√†nh c√¥ng v·ªõi d·ªØ li·ªáu ƒë√£ c·∫≠p nh·∫≠t
    updated_user = {
        "id": "12345",
        "fullName": data.get('fullName', 'Ng∆∞·ªùi D√πng Demo'),
        "email": data.get('email', 'demo@example.com'),
        "phone": data.get('phone', '0123456789'),
        "createdAt": "2023-01-01T00:00:00"
    }
    
    return jsonify({
        "success": True,
        "user": updated_user
    })

# ============ Route predict ƒë√£ c·∫£i thi·ªán ============

@app.route("/predict", methods=["POST"])
def predict():
    if "file" not in request.files:
        return jsonify({"error": "Kh√¥ng c√≥ file ƒë∆∞·ª£c g·ª≠i l√™n"}), 400
    
    file = request.files["file"]
    try:
        # ƒê·ªçc ·∫£nh t·ª´ file g·ª≠i l√™n
        image = Image.open(io.BytesIO(file.read()))
        
        # B∆Ø·ªöC 0: Ki·ªÉm tra c·∫£i thi·ªán cho m√¥i tr∆∞·ªùng t·ª± nhi√™n
        if not enhanced_leaf_detection(image):
            return jsonify({
                "predicted_label": "Kh√¥ng ph·∫£i l√° c√¢y ho·∫∑c ·∫£nh kh√¥ng r√µ",
                "confidence": "95.00%", 
                "is_leaf": False,
                "suggestion": "Th·ª≠ ch·ª•p g·∫ßn h∆°n v√†o l√° c√† ph√™ ho·∫∑c c·∫£i thi·ªán √°nh s√°ng. ƒê·∫£m b·∫£o c√≥ √≠t nh·∫•t 25% di·ªán t√≠ch ·∫£nh l√† l√° xanh."
            })
        
        # Ti·ªÅn x·ª≠ l√Ω ·∫£nh cho model coffee vs not_coffee
        # S·ª≠ d·ª•ng preprocessing c·∫£i thi·ªán cho m√¥i tr∆∞·ªùng t·ª± nhi√™n
        processed_coffee = preprocess_for_natural_environment(image)

        # ====== B∆∞·ªõc 1: Model coffee vs not_coffee ======
        preds_coffee = model_coffee.predict(processed_coffee)
        
        # X√°c ƒë·ªãnh x√°c su·∫•t not_coffee
        prob_not_coffee = float(preds_coffee[0][0])
        
        # ƒêi·ªÅu ch·ªânh ng∆∞·ª°ng cho m√¥i tr∆∞·ªùng t·ª± nhi√™n (gi·∫£m t·ª´ 0.85 xu·ªëng 0.75)
        if prob_not_coffee > 0.75:
            return jsonify({
                "predicted_label": "C√≥ th·ªÉ kh√¥ng ph·∫£i l√° c√† ph√™",
                "confidence": f"{prob_not_coffee * 100:.2f}%",
                "is_leaf": True,
                "suggestion": "ƒê·ªÉ c√≥ k·∫øt qu·∫£ ch√≠nh x√°c h∆°n, h√£y ch·ª•p l√° ri√™ng l·∫ª v·ªõi n·ªÅn ƒë∆°n gi·∫£n v√† √°nh s√°ng t·ªët."
            })
        else:
            # ====== B∆∞·ªõc 2: Model ph√¢n lo·∫°i b·ªánh l√° c√† ph√™ ======
            # Ti·ªÅn x·ª≠ l√Ω ·∫£nh cho model b·ªánh l√° (ch√∫ √Ω kh√°c v·ªõi model coffee)
            processed_disease = preprocess_image(image, is_coffee_model=False)
            
            # D·ª± ƒëo√°n b·ªánh v·ªõi model categorical
            preds_disease = model_disease.predict(processed_disease)
            
            # Chuy·ªÉn v·ªÅ index c·ªßa l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t
            class_id = int(np.argmax(preds_disease, axis=1)[0])
            predicted_label = LABELS_DISEASE[class_id]
            confidence = float(np.max(preds_disease) * 100.0)
            
            # Th√™m l·ªùi khuy√™n d·ª±a tr√™n ƒë·ªô tin c·∫≠y v√† m√¥i tr∆∞·ªùng
            suggestion = ""
            if confidence < 80:
                suggestion = "ƒê·ªô tin c·∫≠y th·∫•p. ƒê·ªÉ c√≥ k·∫øt qu·∫£ ch√≠nh x√°c h∆°n, h√£y ch·ª•p l√° ri√™ng l·∫ª v·ªõi n·ªÅn ƒë∆°n gi·∫£n v√† √°nh s√°ng t·ª± nhi√™n."
            elif 0.65 < prob_not_coffee <= 0.75:
                coffee_confidence = (1 - prob_not_coffee) * 100
                suggestion = "L√° c√≥ v·∫ª nh∆∞ c√† ph√™ nh∆∞ng ch·∫•t l∆∞·ª£ng ·∫£nh c√≥ th·ªÉ ch∆∞a t·ªëi ∆∞u. Th·ª≠ ch·ª•p r√µ n√©t h∆°n."
            
            # N·∫øu n·∫±m ·ªü v√πng kh√¥ng ch·∫Øc ch·∫Øn (0.65-0.75), ƒë∆∞a ra c·∫£nh b√°o
            if 0.65 < prob_not_coffee <= 0.75:
                coffee_confidence = (1 - prob_not_coffee) * 100
                return jsonify({
                    "predicted_label": predicted_label,
                    "confidence": f"{coffee_confidence:.2f}%",
                    "warning": "C√¢y c√≥ th·ªÉ kh√¥ng ph·∫£i c√† ph√™, h√£y ki·ªÉm tra l·∫°i",
                    "is_leaf": True,
                    "suggestion": suggestion or "Th·ª≠ ch·ª•p l√° ri√™ng l·∫ª v·ªõi n·ªÅn ƒë·ªëi l·∫≠p v√† √°nh s√°ng t·ªët h∆°n."
                })
            
            return jsonify({
                "predicted_label": predicted_label,
                "confidence": f"{confidence:.2f}%",
                "is_leaf": True,
                "suggestion": suggestion,
                "natural_environment": True  # ƒê√°nh d·∫•u ƒë√¢y l√† k·∫øt qu·∫£ t·ª´ m√¥i tr∆∞·ªùng t·ª± nhi√™n
            })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ============ Route debug m·ªõi ============

@app.route("/debug/image-analysis", methods=["POST"])
def debug_image_analysis():
    """
    Route debug ƒë·ªÉ ph√¢n t√≠ch chi ti·∫øt ·∫£nh
    """
    if "file" not in request.files:
        return jsonify({"error": "Kh√¥ng c√≥ file ƒë∆∞·ª£c g·ª≠i l√™n"}), 400
    
    file = request.files["file"]
    try:
        image = Image.open(io.BytesIO(file.read()))
        image_np = np.array(image)
        
        # Ph√¢n t√≠ch m√†u s·∫Øc
        hsv = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV)
        lower_green = np.array([35, 40, 40])
        upper_green = np.array([85, 255, 255])
        green_mask = cv2.inRange(hsv, lower_green, upper_green)
        green_ratio = np.sum(green_mask > 0) / (image_np.shape[0] * image_np.shape[1])
        
        # Ph√¢n t√≠ch h√¨nh d·∫°ng
        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Th√¥ng tin contour l·ªõn nh·∫•t
        largest_contour_info = {}
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(largest_contour)
            x, y, w, h = cv2.boundingRect(largest_contour)
            aspect_ratio = float(w) / h if h > 0 else 0
            
            largest_contour_info = {
                "area": float(area),
                "aspect_ratio": float(aspect_ratio),
                "width": int(w),
                "height": int(h)
            }
        
        # ƒê·ªô s√°ng trung b√¨nh
        brightness = float(np.mean(image_np) / 255.0)
        
        return jsonify({
            "image_size": image_np.shape,
            "green_ratio": float(green_ratio),
            "brightness": brightness,
            "contours_found": len(contours),
            "largest_contour": largest_contour_info,
            "passes_basic_filter": not has_extreme_non_leaf_features(image),
            "passes_natural_env_filter": detect_coffee_leaves_in_natural_environment(image),
            "overall_assessment": enhanced_leaf_detection(image)
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ============ Ch·∫°y app ============

if __name__ == "__main__":
    print("üåø Coffee Care API - Phi√™n b·∫£n c·∫£i thi·ªán cho m√¥i tr∆∞·ªùng t·ª± nhi√™n")
    print("üì∏ H·ªó tr·ª£ nh·∫≠n di·ªán l√° c√† ph√™ trong ·∫£nh c√≥ nhi·ªÅu l√° v√† n·ªÅn ph·ª©c t·∫°p")
    print("üîß Debug endpoint: POST /debug/image-analysis")
    app.run(host="0.0.0.0", port=5000, debug=True)